{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T08:05:23.015089Z",
     "iopub.status.busy": "2024-07-26T08:05:23.014223Z",
     "iopub.status.idle": "2024-07-26T08:05:29.033867Z",
     "shell.execute_reply": "2024-07-26T08:05:29.033159Z",
     "shell.execute_reply.started": "2024-02-25T17:15:30.727667Z"
    },
    "id": "ycRjhI25UC-P",
    "papermill": {
     "duration": 6.046028,
     "end_time": "2024-07-26T08:05:29.034094",
     "exception": false,
     "start_time": "2024-07-26T08:05:22.988066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2 as cv2\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score \n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Flatten, MaxPooling2D, Dropout, Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T08:05:29.077965Z",
     "iopub.status.busy": "2024-07-26T08:05:29.077297Z",
     "iopub.status.idle": "2024-07-26T08:05:29.099673Z",
     "shell.execute_reply": "2024-07-26T08:05:29.098911Z",
     "shell.execute_reply.started": "2024-02-25T17:15:38.711286Z"
    },
    "id": "fMDZHcIuGJLe",
    "papermill": {
     "duration": 0.04537,
     "end_time": "2024-07-26T08:05:29.099805",
     "exception": false,
     "start_time": "2024-07-26T08:05:29.054435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loads the data required for detecting the license plates from cascade classifier.\n",
    "plate_cascade = cv2.CascadeClassifier('../input/ai-indian-license-plate-recognition-data/indian_license_plate.xml')\n",
    "# add the path to 'india_license_plate.xml' file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T08:05:29.148987Z",
     "iopub.status.busy": "2024-07-26T08:05:29.147958Z",
     "iopub.status.idle": "2024-07-26T08:05:29.151022Z",
     "shell.execute_reply": "2024-07-26T08:05:29.150510Z",
     "shell.execute_reply.started": "2024-02-25T17:15:38.737212Z"
    },
    "id": "r6BZ2WY8GJHM",
    "papermill": {
     "duration": 0.03208,
     "end_time": "2024-07-26T08:05:29.151178",
     "exception": false,
     "start_time": "2024-07-26T08:05:29.119098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def detect_plate(img, text=''): # the function detects and perfors blurring on the number plate.\n",
    "    plate_img = img.copy()\n",
    "    roi = img.copy()\n",
    "    plate_rect = plate_cascade.detectMultiScale(plate_img, scaleFactor = 1.2, minNeighbors = 7) # detects numberplates and returns the coordinates and dimensions of detected license plate's contours.\n",
    "    for (x,y,w,h) in plate_rect:\n",
    "        roi_ = roi[y:y+h, x:x+w, :] # extracting the Region of Interest of license plate for blurring.\n",
    "        plate = roi[y:y+h, x:x+w, :]\n",
    "        cv2.rectangle(plate_img, (x+2,y), (x+w-3, y+h-5), (51,181,155), 3) # finally representing the detected contours by drawing rectangles around the edges.\n",
    "    if text!='':\n",
    "        plate_img = cv2.putText(plate_img, text, (x-w//2,y-h//2), \n",
    "                                cv2.FONT_HERSHEY_COMPLEX_SMALL , 0.5, (51,181,155), 1, cv2.LINE_AA)\n",
    "        \n",
    "    return plate_img, plate # returning the processed image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T08:05:29.205234Z",
     "iopub.status.busy": "2024-07-26T08:05:29.204203Z",
     "iopub.status.idle": "2024-07-26T08:05:29.207208Z",
     "shell.execute_reply": "2024-07-26T08:05:29.206620Z",
     "shell.execute_reply.started": "2024-02-25T17:15:38.750827Z"
    },
    "papermill": {
     "duration": 0.037247,
     "end_time": "2024-07-26T08:05:29.207336",
     "exception": false,
     "start_time": "2024-07-26T08:05:29.170089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean2_plate(plate):\n",
    "    gray_img = cv2.cvtColor(plate, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    _, thresh = cv2.threshold(gray_img, 110, 255, cv2.THRESH_BINARY)\n",
    "    if cv2.waitKey(0) & 0xff == ord('q'):\n",
    "        pass\n",
    "    num_contours,hierarchy = cv2.findContours(thresh.copy(),cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    if num_contours:\n",
    "        contour_area = [cv2.contourArea(c) for c in num_contours]\n",
    "        max_cntr_index = np.argmax(contour_area)\n",
    "\n",
    "        max_cnt = num_contours[max_cntr_index]\n",
    "        max_cntArea = contour_area[max_cntr_index]\n",
    "        x,y,w,h = cv2.boundingRect(max_cnt)\n",
    "\n",
    "        if not ratioCheck(max_cntArea,w,h):\n",
    "            return plate,None\n",
    "\n",
    "        final_img = thresh[y:y+h, x:x+w]\n",
    "        return final_img,[x,y,w,h]\n",
    "\n",
    "    else:\n",
    "        return plate,None\n",
    "\n",
    "def ratioCheck(area, width, height):\n",
    "    ratio = float(width) / float(height)\n",
    "    if ratio < 1:\n",
    "        ratio = 1 / ratio\n",
    "    if (area < 1063.62 or area > 73862.5) or (ratio < 3 or ratio > 6):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def isMaxWhite(plate):\n",
    "    avg = np.mean(plate)\n",
    "    if(avg>=115):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def ratio_and_rotation(rect):\n",
    "    (x, y), (width, height), rect_angle = rect\n",
    "\n",
    "    if(width>height):\n",
    "        angle = -rect_angle\n",
    "    else:\n",
    "        angle = 90 + rect_angle\n",
    "\n",
    "    if angle>15:\n",
    "        return False\n",
    "\n",
    "    if height == 0 or width == 0:\n",
    "        return False\n",
    "\n",
    "    area = height*width\n",
    "    if not ratioCheck(area,width,height):\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T08:05:29.273437Z",
     "iopub.status.busy": "2024-07-26T08:05:29.260356Z",
     "iopub.status.idle": "2024-07-26T08:05:29.560762Z",
     "shell.execute_reply": "2024-07-26T08:05:29.559630Z",
     "shell.execute_reply.started": "2024-02-25T17:15:38.771348Z"
    },
    "papermill": {
     "duration": 0.333134,
     "end_time": "2024-07-26T08:05:29.560953",
     "exception": true,
     "start_time": "2024-07-26T08:05:29.227819",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7bce0d701b9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetect_image_plate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "def detect_image_plate(img):\n",
    "    def clean2_plate(plate):\n",
    "        gray_img = cv2.cvtColor(plate, cv2.COLOR_BGR2GRAY)\n",
    "        _, thresh = cv2.threshold(gray_img, 110, 255, cv2.THRESH_BINARY)\n",
    "        num_contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "        if num_contours:\n",
    "            contour_area = [cv2.contourArea(c) for c in num_contours]\n",
    "            max_cntr_index = np.argmax(contour_area)\n",
    "            max_cnt = num_contours[max_cntr_index]\n",
    "            max_cntArea = contour_area[max_cntr_index]\n",
    "            x, y, w, h = cv2.boundingRect(max_cnt)\n",
    "            if not ratioCheck(max_cntArea, w, h):\n",
    "                return plate, None\n",
    "            final_img = thresh[y:y + h, x:x + w]\n",
    "            return final_img, [x, y, w, h]\n",
    "        else:\n",
    "            return plate, None\n",
    "\n",
    "    def ratioCheck(area, width, height):\n",
    "        ratio = float(width) / float(height)\n",
    "        if ratio < 1:\n",
    "            ratio = 1 / ratio\n",
    "        if (area < 1063.62 or area > 73862.5) or (ratio < 3 or ratio > 6):\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def isMaxWhite(plate):\n",
    "        avg = np.mean(plate)\n",
    "        if avg >= 115:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def ratio_and_rotation(rect):\n",
    "        (x, y), (width, height), rect_angle = rect\n",
    "        if width > height:\n",
    "            angle = -rect_angle\n",
    "        else:\n",
    "            angle = 90 + rect_angle\n",
    "        if angle > 15:\n",
    "            return False\n",
    "        if height == 0 or width == 0:\n",
    "            return False\n",
    "        area = height * width\n",
    "        if not ratioCheck(area, width, height):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "\n",
    "    img = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.Sobel(img, cv2.CV_8U, 1, 0, ksize=3)\n",
    "    _, img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    element = cv2.getStructuringElement(shape=cv2.MORPH_RECT, ksize=(17, 3))\n",
    "    morph_img_threshold = img.copy()\n",
    "    cv2.morphologyEx(src=img, op=cv2.MORPH_CLOSE, kernel=element, dst=morph_img_threshold)\n",
    "    num_contours, hierarchy = cv2.findContours(morph_img_threshold, mode=cv2.RETR_EXTERNAL, method=cv2.CHAIN_APPROX_NONE)\n",
    "    cv2.drawContours(img, num_contours, -1, (0, 255, 0), 1)\n",
    "    fig = plt.figure(figsize=(12, 7))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(morph_img_threshold, cmap='gray')\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "    for i, cnt in enumerate(num_contours):\n",
    "        min_rect = cv2.minAreaRect(cnt)\n",
    "        print(min_rect)\n",
    "        if ratio_and_rotation(min_rect):\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            plate_img = img[y:y + h, x:x + w]\n",
    "            if isMaxWhite(plate_img):\n",
    "                clean_plate, rect = clean2_plate(plate_img)\n",
    "                plt.imshow(clean_plate)\n",
    "                plt.show()\n",
    "                if rect:\n",
    "                    fg = 0\n",
    "                    x1, y1, w1, h1 = rect\n",
    "                    x, y, w, h = x + x1, y + y1, w1, h1\n",
    "                    plate_im = Image.fromarray(clean_plate)\n",
    "                    plt.imshow(plate_im)\n",
    "                    plt.show()\n",
    "                    return plate_im\n",
    "\n",
    "    return None\n",
    "                \n",
    "print(detect_image_plate(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-29T21:41:44.989981Z",
     "iopub.status.busy": "2023-10-29T21:41:44.989603Z",
     "iopub.status.idle": "2023-10-29T21:41:45.230115Z",
     "shell.execute_reply": "2023-10-29T21:41:45.228549Z",
     "shell.execute_reply.started": "2023-10-29T21:41:44.989947Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-25T17:15:39.035449Z",
     "iopub.status.idle": "2024-02-25T17:15:39.035888Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_and_extract_license_plate(input_image_path, kernel_size=3):\n",
    "    # Load the input image and check if it's loaded successfully\n",
    "    image = cv2.imread(input_image_path)\n",
    "    if image is None:\n",
    "        print(\"Error: Could not load the input image.\")\n",
    "        return\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Apply Sobel operator for edge detection\n",
    "    sobelx = cv2.Sobel(blurred, cv2.CV_64F, 1, 0, ksize=kernel_size)\n",
    "    sobely = cv2.Sobel(blurred, cv2.CV_64F, 0, 1, ksize=kernel_size)\n",
    "    gradient_magnitude = cv2.addWeighted(cv2.convertScaleAbs(sobelx), 0.5, cv2.convertScaleAbs(sobely), 0.5, 0)\n",
    "\n",
    "    # Apply morphological operations to extract license plate region\n",
    "    _, thresholded = cv2.threshold(gradient_magnitude, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    eroded = cv2.erode(thresholded, kernel, iterations=1)\n",
    "    dilated = cv2.dilate(eroded, kernel, iterations=1)\n",
    "\n",
    "    # Find contours in the processed image\n",
    "    contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Filter and find the largest rectangular contour (presumed to be the license plate)\n",
    "    max_area = 0\n",
    "    license_plate = None\n",
    "    for contour in contours:\n",
    "        # draw a rectangle around the contour\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        # discard contours that are too large\n",
    "        if w > 0.5 * dilated.shape[1]:\n",
    "            continue\n",
    "        # discard contours that are too small\n",
    "        if h < 0.2 * dilated.shape[0]:\n",
    "            continue\n",
    "        area = w * h\n",
    "        # draw a green rectangle around the contour\n",
    "        if area > max_area:\n",
    "            max_area = area\n",
    "            license_plate = image[y:y+h, x:x+w]\n",
    "            \n",
    "        bounded_image = cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        # display the bounded image\n",
    "        plt.imshow(bounded_image)\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "    if license_plate is not None:\n",
    "        fig = plt.figure(figsize=(12, 8))\n",
    "        titles = [\"Original Image\", \"Grayscale\", \"Blurred\", \"Sobel\", \"Dilated\", \"License Plate\"]\n",
    "        images = [image, gray, blurred, gradient_magnitude, dilated, license_plate]\n",
    "        plt.axis(\"off\")\n",
    "        for i in range(len(images)):\n",
    "            fig.add_subplot(2, 3, i+1)\n",
    "            plt.imshow(images[i], cmap='gray')\n",
    "            plt.title(titles[i])\n",
    "        plt.show()\n",
    "        return license_plate\n",
    "    else:\n",
    "        print(\"No license plate found\")\n",
    "\n",
    "image = process_and_extract_license_plate(\"/kaggle/input/ai-indian-license-plate-recognition-data/car.jpg\")\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-25T17:15:39.036751Z",
     "iopub.status.idle": "2024-02-25T17:15:39.037114Z"
    },
    "id": "RJ8ScvVJGgH_",
    "outputId": "a9bc10bf-339e-422d-980f-d97120e6ac64",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Testing the above function\n",
    "def display(img_, title=''):\n",
    "    img = cv2.cvtColor(img_, cv2.COLOR_BGR2RGB)\n",
    "    fig = plt.figure(figsize=(10,6))\n",
    "    ax = plt.subplot(111)\n",
    "    ax.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "img = cv2.imread('../input/ai-indian-license-plate-recognition-data/car.jpg')\n",
    "display(img, 'input image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-25T17:15:39.037869Z",
     "iopub.status.idle": "2024-02-25T17:15:39.038200Z"
    },
    "id": "TIMcAMmUGgFB",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Getting plate prom the processed image\n",
    "output_img, plate = detect_plate(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-25T17:15:39.039026Z",
     "iopub.status.idle": "2024-02-25T17:15:39.039415Z"
    },
    "id": "zCfOMO__HEUf",
    "outputId": "10a225cc-e32b-45ca-dc61-ddfea614b562",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(output_img, 'detected license plate in the input image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-25T17:15:39.040130Z",
     "iopub.status.idle": "2024-02-25T17:15:39.040509Z"
    },
    "id": "kGk622P-HERv",
    "outputId": "e5fac915-27e2-45da-8a1a-a2a5226049a4",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(plate, 'extracted license plate from the image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-25T17:15:39.041231Z",
     "iopub.status.idle": "2024-02-25T17:15:39.041618Z"
    },
    "id": "MzopHrMvUC-Z",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Match contours to license plate or character template\n",
    "def find_contours(dimensions, img) :\n",
    "\n",
    "    # Find all contours in the image\n",
    "    cntrs, _ = cv2.findContours(img.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Retrieve potential dimensions\n",
    "    lower_width = dimensions[0]\n",
    "    upper_width = dimensions[1]\n",
    "    lower_height = dimensions[2]\n",
    "    upper_height = dimensions[3]\n",
    "    \n",
    "    # Check largest 5 or  15 contours for license plate or character respectively\n",
    "    cntrs = sorted(cntrs, key=cv2.contourArea, reverse=True)[:15]\n",
    "    \n",
    "    ii = cv2.imread('contour.jpg')\n",
    "    \n",
    "    x_cntr_list = []\n",
    "    target_contours = []\n",
    "    img_res = []\n",
    "    for cntr in cntrs :\n",
    "        # detects contour in binary image and returns the coordinates of rectangle enclosing it\n",
    "        intX, intY, intWidth, intHeight = cv2.boundingRect(cntr)\n",
    "        \n",
    "        # checking the dimensions of the contour to filter out the characters by contour's size\n",
    "        if intWidth > lower_width and intWidth < upper_width and intHeight > lower_height and intHeight < upper_height :\n",
    "            x_cntr_list.append(intX) #stores the x coordinate of the character's contour, to used later for indexing the contours\n",
    "\n",
    "            char_copy = np.zeros((44,24))\n",
    "            # extracting each character using the enclosing rectangle's coordinates.\n",
    "            char = img[intY:intY+intHeight, intX:intX+intWidth]\n",
    "            char = cv2.resize(char, (20, 40))\n",
    "            \n",
    "            cv2.rectangle(ii, (intX,intY), (intWidth+intX, intY+intHeight), (50,21,200), 2)\n",
    "            plt.imshow(ii, cmap='gray')\n",
    "\n",
    "            # Make result formatted for classification: invert colors\n",
    "            char = cv2.subtract(255, char)\n",
    "\n",
    "            # Resize the image to 24x44 with black border\n",
    "            char_copy[2:42, 2:22] = char\n",
    "            char_copy[0:2, :] = 0\n",
    "            char_copy[:, 0:2] = 0\n",
    "            char_copy[42:44, :] = 0\n",
    "            char_copy[:, 22:24] = 0\n",
    "\n",
    "            img_res.append(char_copy) # List that stores the character's binary image (unsorted)\n",
    "            \n",
    "    # Return characters on ascending order with respect to the x-coordinate (most-left character first)\n",
    "            \n",
    "    plt.show()\n",
    "    # arbitrary function that stores sorted list of character indeces\n",
    "    indices = sorted(range(len(x_cntr_list)), key=lambda k: x_cntr_list[k])\n",
    "    img_res_copy = []\n",
    "    for idx in indices:\n",
    "        img_res_copy.append(img_res[idx])# stores character images according to their index\n",
    "    img_res = np.array(img_res_copy)\n",
    "\n",
    "    return img_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-25T17:15:39.042276Z",
     "iopub.status.idle": "2024-02-25T17:15:39.042679Z"
    },
    "id": "h23diSmEUC-e",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find characters in the resulting images\n",
    "def segment_characters(image) :\n",
    "\n",
    "    # Preprocess cropped license plate image\n",
    "    img_lp = cv2.resize(image, (333, 75))\n",
    "    img_gray_lp = cv2.cvtColor(img_lp, cv2.COLOR_BGR2GRAY)\n",
    "    _, img_binary_lp = cv2.threshold(img_gray_lp, 200, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    img_binary_lp = cv2.erode(img_binary_lp, (3,3))\n",
    "    img_binary_lp = cv2.dilate(img_binary_lp, (3,3))\n",
    "\n",
    "    LP_WIDTH = img_binary_lp.shape[0]\n",
    "    LP_HEIGHT = img_binary_lp.shape[1]\n",
    "\n",
    "    # Make borders white\n",
    "    img_binary_lp[0:3,:] = 255\n",
    "    img_binary_lp[:,0:3] = 255\n",
    "    img_binary_lp[72:75,:] = 255\n",
    "    img_binary_lp[:,330:333] = 255\n",
    "\n",
    "    # Estimations of character contours sizes of cropped license plates\n",
    "    dimensions = [LP_WIDTH/6,\n",
    "                       LP_WIDTH/2,\n",
    "                       LP_HEIGHT/10,\n",
    "                       2*LP_HEIGHT/3]\n",
    "    plt.imshow(img_binary_lp, cmap='gray')\n",
    "    plt.show()\n",
    "    cv2.imwrite('contour.jpg',img_binary_lp)\n",
    "\n",
    "    # Get contours within cropped license plate\n",
    "    char_list = find_contours(dimensions, img_binary_lp)\n",
    "\n",
    "    return char_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-25T17:15:39.043459Z",
     "iopub.status.idle": "2024-02-25T17:15:39.043785Z"
    },
    "id": "OGhFmSnYUC-j",
    "outputId": "e9aea986-3422-4173-b4d8-11582f80d2c2",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's see the segmented characters\n",
    "char = segment_characters(plate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-25T17:15:39.044443Z",
     "iopub.status.idle": "2024-02-25T17:15:39.044771Z"
    },
    "id": "rZoiyrDaUC-p",
    "outputId": "e9210536-ff7e-4214-ce8a-ff1274656036",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(char[i], cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QXhqHfXLUC-9",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Model for characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-25T17:15:39.045381Z",
     "iopub.status.idle": "2024-02-25T17:15:39.045716Z"
    },
    "id": "BhrsmfX9UC_p",
    "outputId": "55577343-eb1d-4980-99c0-59ecf8eefd99",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, width_shift_range=0.1, height_shift_range=0.1)\n",
    "path = '../input/ai-indian-license-plate-recognition-data/data/data'\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        path+'/train',  # this is the target directory\n",
    "        target_size=(28,28),  # all images will be resized to 28x28\n",
    "        batch_size=1,\n",
    "        class_mode='sparse')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "        path+'/val',  # this is the target directory\n",
    "        target_size=(28,28),  # all images will be resized to 28x28 batch_size=1,\n",
    "        class_mode='sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-25T17:15:39.046443Z",
     "iopub.status.idle": "2024-02-25T17:15:39.046771Z"
    },
    "id": "WXdiO1Kq9kPI",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Metrics for checking the model performance while training\n",
    "def f1score(y, y_pred):\n",
    "  return f1_score(y, tf.math.argmax(y_pred, axis=1), average='micro') \n",
    "\n",
    "def custom_f1score(y, y_pred):\n",
    "  return tf.py_function(f1score, (y, y_pred), tf.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-25T17:15:39.047456Z",
     "iopub.status.idle": "2024-02-25T17:15:39.047780Z"
    },
    "id": "8IjCdBYrp4EK",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (22,22), input_shape=(28, 28, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(32, (16,16), input_shape=(28, 28, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, (8,8), input_shape=(28, 28, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, (4,4), input_shape=(28, 28, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(36, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizers.Adam(lr=0.0001), metrics=[custom_f1score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-25T17:15:39.048522Z",
     "iopub.status.idle": "2024-02-25T17:15:39.048867Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-25T17:15:39.049621Z",
     "iopub.status.idle": "2024-02-25T17:15:39.049968Z"
    },
    "id": "w5aaqsHABUwx",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class stop_training_callback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('val_custom_f1score') > 0.99):\n",
    "      self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-25T17:15:39.050882Z",
     "iopub.status.idle": "2024-02-25T17:15:39.051222Z"
    },
    "id": "KPAtDd_Jp4BP",
    "outputId": "77203b1e-c29d-408a-8ae4-8707569449a8",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "callbacks = [stop_training_callback()]\n",
    "model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch = train_generator.samples // batch_size,\n",
    "      validation_data = validation_generator, \n",
    "      epochs = 80, verbose=1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-25T17:15:39.051972Z",
     "iopub.status.idle": "2024-02-25T17:15:39.052307Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-25T17:15:39.053115Z",
     "iopub.status.idle": "2024-02-25T17:15:39.053474Z"
    },
    "id": "3PICNwtZUDAD",
    "outputId": "dadfd56e-ecd7-419e-938a-4275f18261d6",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predicting the output\n",
    "def fix_dimension(img): \n",
    "  new_img = np.zeros((28,28,3))\n",
    "  for i in range(3):\n",
    "    new_img[:,:,i] = img\n",
    "  return new_img\n",
    "  \n",
    "def show_results():\n",
    "    dic = {}\n",
    "    characters = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "    for i,c in enumerate(characters):\n",
    "        dic[i] = c\n",
    "\n",
    "    output = []\n",
    "    for i,ch in enumerate(char): #iterating over the characters\n",
    "        img_ = cv2.resize(ch, (28,28), interpolation=cv2.INTER_AREA)\n",
    "        img = fix_dimension(img_)\n",
    "        img = img.reshape(1,28,28,3) #preparing image for the model\n",
    "        y_ = model.predict_classes(img)[0] #predicting the class\n",
    "        character = dic[y_] #\n",
    "        output.append(character) #storing the result in a list\n",
    "        \n",
    "    plate_number = ''.join(output)\n",
    "    \n",
    "    return plate_number\n",
    "\n",
    "print(show_results())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-25T17:15:39.054140Z",
     "iopub.status.idle": "2024-02-25T17:15:39.054493Z"
    },
    "id": "urZpH4YFUDAI",
    "outputId": "e0ac44da-d228-4e4f-a609-0eef4b9614da",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Segmented characters and their predicted value.\n",
    "plt.figure(figsize=(10,6))\n",
    "for i,ch in enumerate(char):\n",
    "    img = cv2.resize(ch, (28,28), interpolation=cv2.INTER_AREA)\n",
    "    plt.subplot(3,4,i+1)\n",
    "    plt.imshow(img,cmap='gray')\n",
    "    plt.title(f'predicted: {show_results()[i]}')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-25T17:15:39.055181Z",
     "iopub.status.idle": "2024-02-25T17:15:39.055513Z"
    },
    "id": "uBboEZgAUDAT",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plate_number = show_results()\n",
    "output_img, plate = detect_plate(img, plate_number)\n",
    "# display(output_img, 'detected license plate number in the input image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 827967,
     "sourceId": 1414839,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 29994,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 10.941288,
   "end_time": "2024-07-26T08:05:29.767263",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-26T08:05:18.825975",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
